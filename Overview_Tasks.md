URCA: 3D video & 3D performance capture virtual & augmented Reality

The problem:
- Due to using cheap and easy-to-use systems, such as depth cameras, it is quite 
difficult to capture the styles on site, such as: calibration, sensor positioning. Hence, my tasks aim at developing innovative approaches to make a 
system be available for normal users and helping them to capture the styles.
Besides, it is hoped that future users can experiment this dance in our equipment
as if being presented by particular dancer. Our proposed method would be based
on the previous works at UR2 and URCA. They uses the data from several sources, such as: raw depth images, RGB images and reconstructed skeleton data delivered by one or a set of depth cameras

There are some sub-tasks:
- develop new approaches to fuse between the various available information and previously collected data. it
aims at correcting the inaccurate data from the depth cameras. And then we will be able to adapt the
resulting data to compatible with the DanceDB database, also used in the other WPS. The big question here is 
'What is the requirements of data in the task and the quality of DanceDB database'
- explore multi-Kinect capture by designing a simple calibration method and fusion of information
- enrich partial data by using priors existing data from the dance DB 
- build a large set of experiments with APs can enable to evaluate the weakness of th resulting system
- 

My task is about WP3
- data processing- 
