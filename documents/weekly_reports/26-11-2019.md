# Comparison between Vicon system and Kinect v1, v2
## Current RGBD cameras
| Camera  	| FPS	 | Dep Reso  | angle (col/depth) | range	| Color reso  | OS	    | Sofware		        | Price		|
| ------- 	| ------ | --------- | ----------------- | ------------ | ----------- | ----------- | ------------------------  | ------------- |
| D435    	| 90   	 | 1280x720  | 85.2x58x94	 | 0.2-10	| 1920x1080   | Win8 +      | SDK Real Sense v2		| 170$		|
| F200    	| 60	 | 640x480   | 77/90		 | 0.2-1.2	| 1920x1280   |	Win8 +	    | SDK Real Sense		|		|
| SR300   	| 60     | 640x480   | N/a		 | 0.2-2	| 1080p	      |	Win10	    | SDK Real Sense		|		|
| Astra Pro   	| 30	 | 1280x720  | 60x49.5x73	 | 0.6-8	| 280x960     | Win,Linux   | Orbbec Astra SDK + OpenNI	| 149.99	|
| Structure se  | 60	 | 320x240   | 58x45		 | 0.4-3.5	| 640x480     | MAC,Win     | Window SDK, OpenNI	| 379+		|
| Kinect v.1    | 30	 | 320x240   | 57x43		 | 0.5-5.5	| 640x480     |	Win7+,Linux | Microsoft SDK, OpenNI	|		|
| Kinect v.2    | 30	 | 512x424   | 70x60		 | 0.5-5.5	| 1920x1080   | Win8+       | Microsoft SDK, OpenNI	|		|

- Kinect v.2 can track up to 6 persons simulatenously.

- Kinect has many advantages but the distance range and frame rate of these devices are not good for all the applications. Besides,
 the devices can not be suitable for use outdoors due to the nature of its depth sensor. Secondly, reflecting surfaces and complex geometries may results in unpredictable random measurements and anomalies, this includes partially reflective clothing, and shiny shoes

- the depth map of kinect v1 is bad. With v2, although there is a significant improvements, there are known issues related to the depth data, jittery and fuzzy around edges because it is not representing a visual feed, and instead false colouring calculations of time. These have a wide margin of error when done real time. This fuzziness of the image increases at large distances. It still remains highly sensitive to even minor reflective surfaces.

- In v1, they use 20 joint points to build skeleton and 25 points with v.2. 

- Mostly studies in low cost gait analysis method, they based on skeleton information extracted from Kinect depth images
- The authors in https://ieeexplore.ieee.org/document/6626570 propose a foot-tracking method to be used for a virtual reality application,
and compare the data with their motion tracking marker-based system, concluding that the data
from the Kinect depth images are reliable enough for this task.

- Recently, [217] evaluated the literature describing the concurrent validity of using the Microsoft
Kinect as a gait analysis instrument. Researchers came to the conclusion that the Kinect is valid
only for estimating a subset of spatiotemporal gait parameters. Kinematic parameters measure-
ments show large errors and are not consistent enough for clinical assessment. However, in the
same year, in a very detailed report by [213], Otto et al. conclude positively on the possibility to
use the Kinect v.2 for motion assessment for a healthy population. Nonetheless, they mention that
signals of feet and ankles had the lowest accuracy according to the mean 3D distance and corre-
lation analysis in XYZ dimensions in comparison to the golden standard measurement. According
to the research, these landmarks are very unstable and thus not reliable.
Several studies have demonstrated that spatiotemporal gait parameters can be reliably obtained
using a single Kinect v.1 sensor [143, 115] and lately using a single [182, 217] and multi [175, 191]
Kinect v.2 sensor. Researchers attempted to both measure the accuracy of Kinect landmarks
and gait parameters extracted from them. Since kinematic and spatial parameters estimated
from Kinect data

- kinect and markers based system:
	- Clark et al. [115] estimated that gait speed, step length, stride length and landmark location lin-
	earity from the Kinect and a marker-based system exhibited excellent similarity. The foot swing
	velocity, step time and stride time possessed excellent and modest relative agreements, but mod-
	est overall (we assume the authors mean absolute) agreement.
	- Mentiplay [182] has shown an excellent step time similarities for the
	Kinect v.2 sensor and Vicon 3D motion analysis.
	- [191] measure mean offsets for all the joints
	for Vicon, Kinect v.1 and Kinect v.2 skeletons and report a big offset for the low-limbs joints for
	both camera versions, especially on the side of the skeleton that is turned further away from the
	camera as the occlusion of joints increases the uncertainty of the pose detection. The orientation
	of the feet is stated as unreliable. Geers et al. [175] performed a kinematic validation of a multi-
	Kinect v.2 instrumented 10-meter walkway for quantitative gait assessments and concluded that
	the Kinect values correspond well to the Optotrac [7] active-marker 3D optical tracking values
 	- The between-systems agreement was examined for raw data, i.e., body point’s time series, and
	spatiotemporal gait parameters, e.g., step length, cadence and step width. In addition, the
	between-systems agreement for the performance measure of the 10MWT, i.e., time to walk 10
	meters, is compared. The test showed good to excellent alignment in body point’s time series be-
	tween the two motion-registration systems according to intraclass correlation indexes [22]. Later
	Geerse at al. extended their previous work to validate foot placement locations from ankle data of
	a Kinect v.2 sensor in comparison with a golden standard system [231]. Researchers found sig-
	nificant between-systems differences in foot placement locations and step lengths in a distance of
	2 meters. This detected effect was likely caused by differences in body orientation relative to the
	Kinect sensor.
# Some metioned motion capture system for dancers
- 
# Motion descriptors

